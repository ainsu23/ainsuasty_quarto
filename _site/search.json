[
  {
    "objectID": "rworld/DataScience/HOML_tidymodels.html",
    "href": "rworld/DataScience/HOML_tidymodels.html",
    "title": "Hands On Machine Learning with R",
    "section": "",
    "text": "Getting very good understanding and skilled applying machine learning it is very important, for this reason, I started learning with the book hands on machine learning with tidymodels\nThis post contains notes and solutions to the exercises for each chapter of the book."
  },
  {
    "objectID": "rworld/DataScience/HOML_tidymodels.html#data-splitting-rsample",
    "href": "rworld/DataScience/HOML_tidymodels.html#data-splitting-rsample",
    "title": "Hands On Machine Learning with R",
    "section": "1. Data Splitting {rsample}",
    "text": "1. Data Splitting {rsample}\nMachine learning models requires data in order to teach the model. This data needs to be separated in two. Data used from package: {modeldata}\n\nsimple sampleStratified sampleDown-SamplingUp-Sampling\n\n\n\nset.seed(123)  # for reproducibility\nsplit <- rsample::initial_split(modeldata::attrition, prop = 0.7)\ntrain <- rsample::training(split)\ntest <- rsample::testing(split)\nrbind(\n  table(train$Attrition) %>% prop.table(),\n  table(test$Attrition) %>% prop.table()\n) %>% as_tibble()\n\n# A tibble: 2 × 2\n     No   Yes\n  <dbl> <dbl>\n1 0.843 0.157\n2 0.830 0.170\n\n\n\n\nIn case the variable response has imbalance, the split process should use stratify, this helps to keep distribution of the response variable in the splitted data.\n\nset.seed(123)  # for reproducibility\nsplit <- rsample::initial_split(modeldata::attrition, prop = 0.7,strata = \"Attrition\")\ntrain <- rsample::training(split)\ntest <- rsample::testing(split)\n\nrbind(\n  table(train$Attrition) %>% prop.table(),\n  table(test$Attrition) %>% prop.table()\n) %>% as_tibble()\n\n# A tibble: 2 × 2\n     No   Yes\n  <dbl> <dbl>\n1 0.839 0.161\n2 0.837 0.163\n\n\n\n\n“Down-sampling balances the dataset by reducing the size of the abundant class(es) to match the frequencies in the least prevalent class. This method is used when the quantity of data is sufficient. By keeping all samples in the rare class and randomly selecting an equal number of samples in the abundant class.”\n\n\n“On the contrary, up-sampling is used when the quantity of data is insufficient. It tries to balance the dataset by increasing the size of rarer samples. Rather than getting rid of abundant samples, new rare samples are generated by using repetition or bootstrapping”\n\n\n\n\nTrain Data\nTrain Data “used to develop feature sets, train our algorithms, tune hyperparameters, compare models, and all of the other activities required to choose a final model (e.g., the model we want to put into production).”\n\n\n\n\nflowchart LR\n  id1[(DataBase)]  --> A((Train))\n  subgraph Training\n    direction TB\n    subgraph Resampling\n    B[resample 1]\n    C[resample 2]\n    D[resample 3]\n    end\n    subgraph Model_1\n    E[Develop] --> F[Evaluate]\n    G[Develop] --> H[Evaluate]\n    I[Develop] --> J[Evaluate]\n    end\n    subgraph Model_2\n    K[Develop] --> L[Evaluate]\n    M[Develop] --> N[Evaluate]\n    O[Develop] --> P[Evaluate]\n    end\n    subgraph Model_n\n    Q[Develop] --> R[Evaluate]\n    S[Develop] --> T[Evaluate]\n    U[Develop] --> V[Evaluate]\n    end\n  end \n  A -- Data into samples --> Resampling\n  Resampling -- Create --> Model_1\n  Model_1 -- Tune --> Model_2\n  Model_2 -- Tune --> Model_n\n  \n\n\n\n\n\n\n\n\nOnce the best model is selected it is time to test the model with the test data. Training (60% - 80%) and Testing (40% - 20%). It’s importante to not pass this limits because you can fall in a overfitting.\n\n\nTest data\nTest data: “having chosen a final model, these data are used to estimate an unbiased assessment of the model’s performance, which we refer to as the generalization error.”"
  },
  {
    "objectID": "rworld/DataScience/HOML_tidymodels.html#modelling-in-r",
    "href": "rworld/DataScience/HOML_tidymodels.html#modelling-in-r",
    "title": "Hands On Machine Learning with R",
    "section": "2. Modelling in R",
    "text": "2. Modelling in R\nThere are different ways to create a formulas depending on the engine used. In order to test the model, we should not use the test data, instead, training data should be splitied using resampling methods,"
  },
  {
    "objectID": "rworld/DataScience.html",
    "href": "rworld/DataScience.html",
    "title": "Data Science",
    "section": "",
    "text": "Hands On Machine Learning with R\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "rworld/Shiny/data_structures.html",
    "href": "rworld/Shiny/data_structures.html",
    "title": "Data Structures",
    "section": "",
    "text": "Go to App\nCheck code here\n\nThe idea behind this application is to learn and create apps from data structures field.\nDouble linked list representation with random words. The user should guess the word from the wordcloud, the letters introduced are compared to a linkedlist saved in a R6Class."
  },
  {
    "objectID": "rworld/Shiny/learning_polish.html",
    "href": "rworld/Shiny/learning_polish.html",
    "title": "Learning Polish",
    "section": "",
    "text": "Go to App\nCheck code here\n\nThis application contains different modules:\n\nVocabulary: Connects with google firebase where data for this app is stored. In that way, words can be added, deleted or modified in real time using R functions\nGames: Contains two games\n\nBucket list: Drag and drop words into categories\nGuess word: Guess word in the correct order"
  },
  {
    "objectID": "rworld/Shiny/mastering_shiny.html",
    "href": "rworld/Shiny/mastering_shiny.html",
    "title": "Mastering Shiny",
    "section": "",
    "text": "This application solves exercises proposed on each chapter of the book.\n\nGo to App\nCheck code here"
  },
  {
    "objectID": "rworld/Shiny.html",
    "href": "rworld/Shiny.html",
    "title": "Shiny",
    "section": "",
    "text": "Data Structures\n\n\nApp with application of Data Structures\n\n\n\nR6Class\n\n\nData Structures\n\n\n\nApp to develop data structure applications\n\n\n\n\n\n\n\n\n\n\n\n\n\nLearning Polish\n\n\nApp with interactive games.\n\n\n\nfirebase\n\n\nAPI\n\n\n\nApp created to learn polish in an interactive way with games developed\n\n\n\n\n\n\n\n\n\n\n\n\n\nMastering Shiny\n\n\nBy Hadley Wickham\n\n\n\nmodules\n\n\n\nSolution to exercices mastering Shiny’s book.\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "rworld.html",
    "href": "rworld.html",
    "title": "RWorld",
    "section": "",
    "text": "Blog\n\n\nR, Python, SQL, Spark, among others\n\n\nGeneral tips for R, Git, SQL or python.\n\n\n\n\n\n\n\n\n\n\n\n\n\nData Science\n\n\nWith tidymodels\n\n\nMachine learning models developed with tidymodels\n\n\n\n\n\n\n\n\n\n\n\n\n\nShiny\n\n\nApps\n\n\nDashboards created with Shiny library for R\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Andrés Felipe Insuasty Ch.",
    "section": "",
    "text": "Hola | Hi | Cześć\nI love learn and share what I have learned, for that reason, I share with you personal experiences and profesional projects developing Data Science."
  },
  {
    "objectID": "rworld/DataScience/HOML_tidymodels.html#resampling-methods",
    "href": "rworld/DataScience/HOML_tidymodels.html#resampling-methods",
    "title": "Hands On Machine Learning with R",
    "section": "3. Resampling methods",
    "text": "3. Resampling methods\n“Provide an alternative approach by allowing us to repeatedly fit a model of interest to parts of the training data and test its performance on other parts. The two most commonly used resampling methods include k-fold cross validation and bootstrapping.”\n\nK-fold cross validationBootstrapping\n\n\nPrincipal idea of k-fold where the training data is divided into training samples and one testing sample, so you can test within the fold created. This procedure is repeated k times. In practices, k = 5 or k = 10 is common.\n“Although using k ≥ 10 helps to minimize the variability in the estimated performance, k-fold CV still tends to have higher variability than bootstrapping (discussed next). Kim (2009) showed that repeating k-fold CV can help to increase the precision of the estimated generalization error. Consequently, for smaller data sets (say n<10,000, 10-fold CV repeated 5 or 10 times will improve the accuracy of your estimated performance and also provide an estimate of its variability.”\n\nrsample::vfold_cv(modeldata::ames, v = 10)\n\n#  10-fold cross-validation \n# A tibble: 10 × 2\n   splits             id    \n   <list>             <chr> \n 1 <split [2637/293]> Fold01\n 2 <split [2637/293]> Fold02\n 3 <split [2637/293]> Fold03\n 4 <split [2637/293]> Fold04\n 5 <split [2637/293]> Fold05\n 6 <split [2637/293]> Fold06\n 7 <split [2637/293]> Fold07\n 8 <split [2637/293]> Fold08\n 9 <split [2637/293]> Fold09\n10 <split [2637/293]> Fold10\n\n\n\n\nRandom samples of the data with replacement “Since observations are replicated in bootstrapping, there tends to be less variability in the error measure compared with k-fold CV (Efron 1983). However, this can also increase the bias of your error estimate. This can be problematic with smaller data sets; however, for most average-to-large data sets (say n≥1,000) this concern is often negligible.”\n\nrsample::bootstraps(modeldata::ames, times = 10)\n\n# Bootstrap sampling \n# A tibble: 10 × 2\n   splits              id         \n   <list>              <chr>      \n 1 <split [2930/1062]> Bootstrap01\n 2 <split [2930/1076]> Bootstrap02\n 3 <split [2930/1066]> Bootstrap03\n 4 <split [2930/1045]> Bootstrap04\n 5 <split [2930/1087]> Bootstrap05\n 6 <split [2930/1108]> Bootstrap06\n 7 <split [2930/1075]> Bootstrap07\n 8 <split [2930/1078]> Bootstrap08\n 9 <split [2930/1053]> Bootstrap09\n10 <split [2930/1067]> Bootstrap10\n\n\n\n\n\nFollowing image shows distribution for each approach, each graphs was generated from the book."
  },
  {
    "objectID": "rworld/DataScience/HOML_tidymodels.html#bias-variance-trade-off",
    "href": "rworld/DataScience/HOML_tidymodels.html#bias-variance-trade-off",
    "title": "Hands On Machine Learning with R",
    "section": "4. Bias variance trade-off",
    "text": "4. Bias variance trade-off\nBias variance trade-off"
  },
  {
    "objectID": "rworld/DataScience/HOML_tidymodels.html#model-evaluation",
    "href": "rworld/DataScience/HOML_tidymodels.html#model-evaluation",
    "title": "Hands On Machine Learning with R",
    "section": "5. Model evaluation",
    "text": "5. Model evaluation\nModel evaluation"
  },
  {
    "objectID": "rworld/DataScience/HOML_tidymodels.html#target-engineering",
    "href": "rworld/DataScience/HOML_tidymodels.html#target-engineering",
    "title": "Hands On Machine Learning with R",
    "section": "1. Target Engineering",
    "text": "1. Target Engineering\nSome models, for example, parametrics ones. Assumes that their response variable and the error are normally distributed. Therefore, it is important to review distribution before start modelling, this might improve the prediction.\nOne way to correct not normally distribution is with the log or BoxCox function. “However, we should think of the preprocessing as creating a blueprint to be re-applied strategically. For this, you can use the recipe package or something similar (e.g., caret::preProcess()). This will not return the actual log transformed values but, rather, a blueprint to be applied later.”\n\n# Log transformation applied to all outcomes\names_recipe <- recipe(Sale_Price ~ ., data = ames_train) %>%\n  step_log(all_outcomes()) # OR\n  # step_BoxCox(all_outcomes())\n\nIn case the response variable has negatives, the previous approach might conduct to NAs values, then, step_YeoJohnson() can be applied."
  },
  {
    "objectID": "rworld/DataScience/HOML_tidymodels.html#dealing-with-missingness",
    "href": "rworld/DataScience/HOML_tidymodels.html#dealing-with-missingness",
    "title": "Hands On Machine Learning with R",
    "section": "2. Dealing with missingness",
    "text": "2. Dealing with missingness\nI strongly recommend to use naniar package to check missings values in the df. naniar::vis_miss()\n\nSome missing values might be an error caused by the construction of the data, so, this requires to analyse. In case, Data is well built, imputation values can be used. Please check the following:"
  }
]